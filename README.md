# web-crawler-experiment

An experiment where an automated script continuously read the page and scrap data from it, this was slightly altered to check if a "new entry" was added post the first initialization of the script.

Does this task every 30 seconds and save everything into a log documenting all changes that occured.

# Packages Used

* `requests | pip install requests` for requesting the website.
* `BeautifulSoup | pip install BeautifulSoup` to read it in plain HTML and get exactly the specific data from the requested content
* Rest are default Python libraries (Note: This is mainly for Windows because of "winsound").

![](https://i.imgur.com/9IGfjq1.png)
