# web-crawler-experiment

An experiment where an automated script continously read the page and harness data from it, this was slightly altered to check if a "new entry" was added post the first initialization of the script.

Does this task every 30 seconds and save everything into a log documenting all changes that occured.

# Packages Used
`requests | pip install requests` for requesting the website.
`BeautifulSoup | pip install BeautifulSoup` to read it in plain HTML and get exactly the specific data from the requested content.
Rest are default Python libraries (Note: This is mainly for Windows because of "winsound").
